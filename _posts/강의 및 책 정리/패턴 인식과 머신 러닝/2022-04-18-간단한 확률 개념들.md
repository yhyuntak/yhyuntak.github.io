---
title: "간단한 확률 개념들"
categories:
  - 패턴 인식과 머신 러닝
toc: false
---

머신러닝에서 선형대수와 더불어 빼놓을 수 없는 개념은 바로 "확률" 입니다. 여기서 가장 기초적인 개념들을 한번 기록해보려고 합니다.

* **확률**
---
  확률 변수를 X,Y라고 설정하면, 우리는 확률 변수 X가 $x_i$일 때의 확률을 다음과 같이 표현합니다.
  
  $$
  p(X=x_i)
  $$

  이것은 모든 확률에서의 기초적인 표현입니다. 

* **joint probability**
---
  그리고 X가 $x_i$이면서 Y가 $y_i$일 확률을 아래와 같이 쓸 수 있으며, 이것을 joint probability라고 부릅니다. 
  
  $$
  p(X=x_i,Y=y_i)
  $$

  joint probability를 통해 우리는 단일 확률 변수에 대한 확률을 계산할 수 있습니다.

* **marginal probability**
---
  만약 X가 $x_i$일 확률을 구하고 싶다면,  Y가 $y_1,y_2,...,y_N$인 joint probability를 다 더해주면 됩니다. 
  
  $$
  p(X=x_i)=\Sigma^N_{j=1}p(X=x_i,Y=y_j)
  $$
  
  이것을 우리는 sum rule이라고 부르고, 위 방법으로 얻게 된 X가 $x_i$일 확률을 marginal probability라고 부릅니다.

* **conditional probability**
---
  sum rule과 달리, yi에 대한 xi인 확률은 다음과 같이 표현하며 이것을 conditional probability라고 부릅니다.

  $$
  p(X=x_i|y=y_i)
  $$

* **product rule**
---
  sum rule과 더불어 중요한 개념 중 하나가 바로 product rule입니다. 
  product rule이란, joint probabilty를 구하기 위해 conditional probability와 marginal probability를 곱하는 것입니다.

  $$
  p(X,Y)=p(X|Y)p(Y)
  $$

* **Bayes rule**
---
  product rule은 베이즈 정리의 핵심 개념이 됩니다. 
  왜냐하면 p(X,Y)=p(Y|X)p(X)가 동시에 성립하기 때문에, 이 식과 위 식을 사용하면 아래와 같이 베이즈 정리를 쓸 수 있기 때문이죠.

  $$
  p(Y|X) = \frac{p(X|Y)p(Y)}{p(X)}
  $$
