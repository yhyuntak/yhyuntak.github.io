---
title: "사이킷런 모음집"
categories:
  - 파이썬 머신러닝 완벽 가이드
toc: false
---

책을 공부하면서 사이킷런 라이브러리에 대해 기록을 모아놓는 곳이다.

# 예제 데이터
---
  
  데이터 셋 이름 목록

  * boston : 미국 보스턴의 집 feature들과 가격 데이터
  * breast_cancer : 위스콘신 유방암 피처들과 악성/음성 레이블 데이터
  * diabetes : 당뇨 데이터
  * digits : 0~9까지의 이미지 데이터
  * iris : 붓꽃에 대한 feature을 가진 데이터

  ```python
  from sklearn.datasets import load_{데이터셋 이름}()
  
  data = load_{데이터 셋 이름}()
    
  ```

  key() 목록
  
  * data : feature 데이터 
  * feature_names : feature의 이름
  * target : label 데이터
  * target_name : label 이름

  
<br/><br/><br/>

# feature 처리
---

<br/><br/><br/>


# 모델
---

대부분의 모델들은 fit과 predict함수를 이용해서 학습을 한다. 가장 처음에 나오는 의사결정트리에 예시를 적어두고, 나머지는 모델만 언급하겠다.
만약에 다른 예시가 나오면, 그때 이야기하도록 하자. 

## Classifier 

* **의사결정트리 (Decision Tree)**

  ```python
  from sklearn.tree import DecisionTreeClassifier
  # 객체 선언
  DT = DecisionTreeClassifier(random_state=N)
  
  # 학습
  DT.fit(train데이터,label데이터)
  
  # 예측
  pred = DT.predict(test데이터)
  ```

## Regressor

<br/><br/><br/>

# 여러 기능
---

## Model selection

* **학습/테스트 데이터 분리 (train_test_split)**

  ```python
  from sklearn.model_selection import train_test_split
  X_train,X_test,y_train,y_test = train_test_split(피쳐 데이터,피쳐 label,test_size=0.3,random_state=N)
  ```

* **K Fold/Stratified K Fold**

  K Fold가 있지만, 데이터 균등 분배를 위해 무조건 Stratified K Fold를 쓰도록 하자.

  ```python
  from sklearn.model_selection import StratifiedKFold
  
  # KFold 객체 선언
  skfold = StratifiedKFold(n_splits=N)
  
  for train_idx,test_idx in skfold.split(피쳐 데이터,label 데이터) :
      # train_idx : train 데이터로 가져갈 인덱스 , test_idx : test 데이터로 가져갈 인덱스
      ...
  ```

* **Stratified K Fold를 이용한 자동 교차 검증(cross_val_score)**
  
  Stratified K Fold를 사용하면 kfold와 모델의 객체 선언, for문 생성 후, 인덱스로 데이터 만들고 fit,predict ... 너무 많은 코딩을 해야한다.
  이를 아주 획기적으로 줄여주는 함수가 cross_val_score()이다.
  
  ```python
  from sklearn.model_selection import cross_val_score
  
  # scores는 scoring의 방식으로 측정한 결과를 반환해줍니다. 
  # cv는 K Fold에서 몇 K로 할 것인지를 표현합니다.
  scores = cross_val_score(모델,학습 데이터,label 데이터,scoring={scoring parameter},cv=N)
  ```
  
  scoring parameter 목록은 [링크](https://scikit-learn.org/stable/modules/model_evaluation.html)에 들어가면 볼 수 있다.

* **최적의 하이퍼 파라미터들을 찾기! (GridSearchCV)**

  모델 객체를 선언할 때, 하이퍼 파라미터들을 선언하는 것은 필수적이다. 그리고 하이퍼 파라미터에 따라 모델의 성능이 좌지우지된다. 
  따라서 최적의 파라미터들을 찾는건 너무 중요하다. 그러나 한번에 딱! 짚어서 찾는건 사실상 불가능하므로, 여러 조합을 만들어서 파악해자.
  이것을 수행해주는 함수가 GridSearchCV()이다. 학습 시, 기본적으로 최적의 파라미터들을 찾고 그것을 모델에 설정해 결과를 도출해준다.
  
  ```python
  from sklearn.model_selection import GridSearchCV
  
  # 객체 선언
  grid_dtree = GridSearchCV(모델,param_grid={하이퍼 파라미터 dictionary},cv=N)
  
  # 학습
  grid_dtree.train(학습 데이터,label 데이터)
  
  # 결과 추출
  scored_df = pd.DataFrame(grid_dtree.cv_results_)
  
  # 최적 파라미터는?
  print("최적의 파라미터 : ",grid_dtree.best_params_)
  
  # 최고 정확도는?
  print("최적의 파라미터 : ",grid_dtree.best_score_)
    
  ```
  
  하이퍼 파라미터들은 dictionary 형식으로 저장되어있어야 한다.


## 평가(Metrics)

* **단순 정확도 계산(accuracy_score)**
  
  ```python
  from sklearn.metrics import accuracy_score
  print("정확도 : {0:.4f}".format(accuracy_score(예측결과,정답)))
  
  ```




