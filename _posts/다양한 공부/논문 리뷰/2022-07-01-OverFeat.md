---
title: "논문 리뷰: OverFeat(2014)"
excerpt : OverFeat에 대한 논문 리뷰
categories:
  - 논문 리뷰
  - Computer Vision
  - Pattern Recognition
  - CNN
toc: true

---

[본 논문 OverFeat](https://arxiv.org/pdf/1312.6229.pdf)은 [FCN 논문](https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Long_Fully_Convolutional_Networks_2015_CVPR_paper.pdf)을 읽던 도중 읽어봐야겠다고 생각되어 읽게 된 논문입니다.

---

# 1. _Introduction_

작은 데이터셋을 가진 CNN네트워크는 점점 분류기의 정확도가 좋아졌지만, 큰 데이터셋을 가진 네트워크에 비빌 수 없었다.

ConvNet들의 가장 큰 이점은 **전체 시스템을 _end to end_로 학습**하는 것이고, 
주된 단점은 **라벨링 데이터가 너무 많이 필요**하다는 것이다.

이 논문의 가장 주목해야할 점은 ***classification과 localization,detection을 하나의 ConvNet으로 학습하는 것**이다.
특히, localization과 detection은 예측된 bounding box들을 쌓아서 할 것이다. localization 예측들을 막 합쳐보면, 
detection은 학습하지 않고 수행할 수 있기에 시간적으로 이득을 보고 복잡한 bootstrapping 학습 과정을 거치지 않아도 된다.
(아마도 이 논문을 기점으로, 이전의 방법들은 3개의 목적을 달성하기 위해 꽤나 복잡한 과정을 거친 듯 하다.)

<br/>

## 1.1 데이터셋의 단점들과 해결을 위한 idea들

실험은 ImageNet의 데이터를 썻는데, 이 데이터셋의 이미지들은 대부분 이미지에 꽉차게 물체가 가운데에 위치하는 것을 볼 수 있다.
그러나 사실 이미지에서 물체의 크기나 위치는 때때로 달라진다. 이를 위한 첫번째 아이디어는 다음과 같다.

* Convnet을 여러 크기들의 window로 이미지의 여러 곳을 적용시키는 것

위 방법은 classification에는 효율적이나, 물체의 전체 혹은 물체의 중심을 학습하는 것은 아니기에, localization과 detection에 있어서 형편없다.
그래서 이를 해결하기 위한 두번째 아이디어는 다음과 같이 학습하는 것이다.

* 각각의 window마다 카테고리들의 distribution을 만들기
* location 예측과 물체를 포함하는 bounding box의 크기를 예측하는 것

세번째 아이디어는 다음과 같다.

* 각각의 카테고리들에 대한 evidence를 각각의 location과 size에서 축적하는 것이다. 

<br/><br/><br/>

# 2. _Vision Tasks_
Compute vision task에 있어서 저자는 classification -> localization -> detection 순으로
난이도가 증가한다고 하며, -> 방향으로 이전의 task는 다음 task의 종속된 task느낌이라고 한다. 

2013년에 열린 ImageNet 대회를 예를 들어보자. 이 대회에선 각각의 task마다 데이터셋도 조금 다르고
목표도 좀 다른 것 같음(?)

<br/>

## 2.1 Classification

각각의 이미지들은 이미지의 main object에 맞는 단일 라벨이 할당되어있다. 올바른 선택을 위해 5개의 예측까지를 허용된다.

<br/>

## 2.2 Localization

이것도 한 이미지당 5개의 추측을 낼 수 있지만, 추가적으로 각각의 추측마다 bounding box도 내야한다.
올바른 답을 고려하는 것은 bounding box의 50%이상이 맞고 classification 또한 맞아야 한다.

<br/>

## 2.3 Detection

이것 localization과 살짝 다른데, 각각의 이미지마다 object가 있을수도, 아님 많을 수도 있다. 
그리고 false positive들(예를 들어, 이미지에 사람이 없는데 사람이 있다고 예측하는 것)은 mean average precision(mAP)에 의해 패널티를 받는다.

<br/><br/><br/>

# 3. _Classification_
저자들의 모델은 ILSVRC12대회의 best model보다 network design이나 inference step을 향상시켰다.
이것에 대한 설명은 나중에 보자.

<br/>

## 3.1 Model Design and Training

저자들은 1.2 백만개의 이미지들과 1000개의 클래스를 갖는 ImageNet 2012 데이터 셋을 학습을 위해 썼다.
학습을 위한 초기 설정 및 입력들은 다음과 같이 했다.

* 처음 input의 size는 고정되어있지만, calssfication을 위해 multi-scale을 취했다.
* 각각의 이미지들은 최소 256 pixel들을 갖게 했으며 추가적으로 221x221 사이즈로 이미지를 5번 랜덤하게 잘라냈다.
* Size of [mini-batch](https://yhyuntak.github.io/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%B0%B0%EC%B9%98-%ED%95%99%EC%8A%B5/) : 128
* Initial weight : randomly with $(\mu,\sigma)=(0,1\times10^{-2})$
* Optimizer : Stochasitc Gradient Descent(SGD) <<SGD에 대해 공부하고 기록하기부터>>
* 