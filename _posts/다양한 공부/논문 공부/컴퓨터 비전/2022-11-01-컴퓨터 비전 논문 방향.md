---
title: "컴퓨터 비전 논문 방향"
excerpt : 본 글은 유명 학회 논문들의 abstract를 읽고 어떤 분야들이 있는지 보기 위한 곳이다.
categories:
  - 논문 리뷰
  - 학회 탐방
toc: true
---

컴퓨터 비전과 관련된 연구들이 뭐가 있는지 abstract만 읽으면서 방향을 알아보자.

# 2021 

## ICCV

[2021년 ICCV](https://openaccess.thecvf.com/ICCV2021)의 논문들을 내가 보고싶은 분야별로 검색해서 봐보자.

### Detection

* [Entropy Maximization and Meta Classification for Out-of-Distribution Detection in Semantic Segmentation](https://openaccess.thecvf.com/content/ICCV2021/papers/Chan_Entropy_Maximization_and_Meta_Classification_for_Out-of-Distribution_Detection_in_Semantic_ICCV_2021_paper.pdf)
  
  이 논문은 아마도 anormaly detection에 관련된 문제 중 Semantic Segementation의 Out-of-Distribution에 대한 이야기를 하는 것 같다.
  > [NOTE] 인터넷을 찾아보니, anormaly detection에 대해 잘 정리된 [호야님의 블로그](https://hoya012.github.io/blog/anomaly-detection-overview-1/)를 찾을 수 있었다. 도움이 많이 되는 사이트가 될 것 같다.

  실제 자율주행과 같은 상황에서 만약 학습한 적 없던 물체를 만났을 땐, 잘못된 인식을 할 수 있다. 그 때를 위해 OoD detection 개념으로 해결하는 듯하다. 
  OoD detection을 접근하는 기본적인 방법이 pixel-wise softmax entropy에 threshold를 잡는 것인데, 이것을 좀 더 향상시키기 위해 2가지 단계로 표현한다고 한다.
  > [후기] anormaly detection 이란 개념에 대해 처음 알게 되었다. 이런 장르도 있구나 싶네.
  
  |![그림](\assets\images\다양한 공부\논문\컴퓨터 비전\방향정리\2021\ICCV\Detection\OoDdetection_entropy.png)|
  |:--:|
  |Figure 1|

  Figure 1에서 baseline의 segmentation mask에서 제일 아래부분이나 중심에 초록색 컨투어가 있는데, 이것은 OoD 데이터이기 때문에 딱 어느 하나의 segmentation이 되면 안될 것이다. 실제로 저자들의 방법의 결과를 보면,
  여러 segmentation으로 되어있고 heatmap이 빨갛게 된 것을 볼 수 있다. 아마 이런 느낌으로 해석하는게 맞을 듯..?

* [Specificity-preserving RGB-D Saliency Detection](https://openaccess.thecvf.com/content/ICCV2021/papers/Zhou_Specificity-Preserving_RGB-D_Saliency_Detection_ICCV_2021_paper.pdf)

  이 논문은 RGB-D saliency detection에 대한 논문이다. 
  > [NOTE] saliency map이란, 관심이 있는 물체를 관심 없는 것들로부터 분리시키는 것을 이야기한다. 더 자세한 설명은 [유니디니님의 블로그](https://go-hard.tistory.com/3)를 참고하자. 
  
  기존의 관련 논문들은 다양한 fusion 전략을 통해서 shared representation을 학습하는데 집중하고, 극소수의 몇몇 방법들만 modality-specific 특성을 어떻게 보존할지 고민한다.
  이 논문은 저 특성을 보존하기 위해 새로운 관점을 제시하는 모양이다. 제시하는 SP-Net(specificity-preserving network)는 shared information과 modality-specific 특성을 고려해 성능 향상을 노린다. 
  > [NOTE] 여기서 modality-specific이 뭔지 모르겠다. modality는 흔히 multi-modality로 사용되는 단어인 것 같다. multi-modality란, 음성,텍스트,이미지 등 다양한 입력들을 결합하여 AI 알고리즘을 만들어 
  엄청난 성능 향상을 꾀하는 새로운 분야라고 한다. [출처](https://www.aimesoft.com/multimodalai.html) 이 관점에서 본다면, modality-specific은 아마 RGB와 Depth 이미지를 결합하는 것을 의미할 것 같다.
  
  |![그림](\assets\images\다양한 공부\논문\컴퓨터 비전\방향정리\2021\ICCV\Detection\rgbd_saliency_map.png)|
  |:--:|
  |Figure 1|

  Figure 1의 (c)를 보면, Conv layer로 Fusion 하는 module을 CIM(crossenhanced intergration module)이라 부르는 것 같고, Decoder에서 feature aggregation 하는 모듈을 multi-modal feature aggregation(MFA) module이라고 한다.
  저런 식으로 해서, 멀티모달 특징들을 상호보완해서 saliency map의 성능을 향상시키려는 것 같다.

[Image Manipulation Detection by Multi-View Multi-Scale Supervision](https://openaccess.thecvf.com/content/ICCV2021/papers/Chen_Image_Manipulation_Detection_by_Multi-View_Multi-Scale_Supervision_ICCV_2021_paper.pdf)

  


### Segementation


# 분야 기록
---

Image Generation :
https://paperswithcode.com/task/image-generation

Knowledge Distillation on ImageNet : https://paperswithcode.com/sota/knowledge-distillation-on-imagenet

Few-Shot Image Classification : 
https://paperswithcode.com/sota/few-shot-image-classification-on-mini-2

Fine-Grained Image Classification : 
https://paperswithcode.com/task/fine-grained-image-classification

Object Detection :
https://paperswithcode.com/task/object-detection


Real-Time Object Detection :
https://paperswithcode.com/task/real-time-object-detection

Semantic Segmentation :
https://paperswithcode.com/task/semantic-segmentation

Instance Segmentation :
https://paperswithcode.com/task/instance-segmentation

Representation Learning :
https://paperswithcode.com/task/representation-learning


Transfer Learning :
https://paperswithcode.com/task/transfer-learning

Question Answering :
https://paperswithcode.com/task/question-answering

Language Modelling :
https://paperswithcode.com/task/language-modelling

Machine Translation: 
https://paperswithcode.com/task/machine-translation

