---
title: "논문 공부: Fast R-CNN(2015)"
excerpt : fast R-CNN에 대해 알아보자.
categories:
  - 컴퓨터 비전
  - 논문 리뷰
  - object detection
toc: true

---

본 글은 [논문 fast R-CNN](https://arxiv.org/abs/1504.08083)을 읽고 공부하는 글입니다.
이전 글 [R-CNN]()에 이어 2번째 시리즈네요.

# 1. _Introduction_
---

2010~2012년에는 [SIFT](chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf),[HOG]()와 같은 것을 베이스로 많은 파생 방법들이 나왔지만, 발전이 저조했다.

SIFT에 대해선 옛날에 공부할때 자주 들렀던 [bskyvision님 블로그의 글](https://bskyvision.com/21)을 보고 오자. 꽤나 재밌다.
HOG에 대해선 구글링을 하자. [링크](https://blog.naver.com/PostView.nhn?blogId=dongju0531hb&logNo=222443993008)도 간단하게 볼 만 하다.

본 논문은 CNN을 이용해서 기존의 방법들보다 object detection 성능을 드라마틱하게 끌어낼 수 있음을 보여준다. 
이것을 위해 2개의 문제에 집중한다.
1. deep network로 물체들의 위치 파악하는 것
2. 적은 양의 데이터로 높은 성능을 내는 모델을 학습하는 것

|![그림 1](\assets\images\다양한 공부\논문\컴퓨터 비전\RCNN\그림 1.png)|
|:--:|
|_그림 1_|

그림 1은 RCNN의 대략적인 구조를 보여준다. 저자들은 localization 문제를 해결하기 위해, 입력 이미지에서 약 2000개의 category-independent region을 제안했고, 각각의 제안에 대해 CNN을 사용해서 고정된 길이의 feature vector를 뽑아냈다.
그리고 linear SVM을 사용해서 카테고리들을 분류했다. {category-independent가 정확히 무슨 뜻인진 모르겠다. 아마 클래스에 무관하게 추출한다는 의미같다.}
추출된 region들은 각각 크기가 다르기 때문에, 이미지를 조절해서 같은 크기로 만들어서 CNN에 넣었다. 

Detection 과정 중 맞이한 또다른 문제는, 라벨링된 데이터가 부족하고 이용가능한 수가 충분치 않아서 큰 CNN 모델을 학습하기 어려웠다. 
그래서 저자들은 **다른 큰 데이터셋들을 이용해서 네트워크로 지도 사전 학습을 했고** 이것은 데이터가 부족한 상황에서 좋은 수용능력을 가진 CNN을 학습하는데 효과적이었다!
즉, **다른 큰 데이터셋들로 모델의 표현력을 이끌어낸 다음, 본 학습에 들어가는게 효과적이다**라는 뜻이다.

그리고 R-CNN은 region을 사용하므로, 자연스럽게 sementic segmentation으로 확장가능하다.

<br/><br/>

# 2. _Object detection with R-CNN_
---

R-CNN은 3가지의 단계로 시스템이 이루어져있다.
1. 카테고리와 상관없이 region들을 제안하기
2. 제안된 영역들에서 CNN을 이용해 고정된 길이의 feature vector들을 추출하기
3. 추출된 feature vector들에 linear SVM을 적용해서 분류하기

이제 각각의 단계에 대해 알아보자.

<br/>

## 2.1. Module design

먼저 1,2단계에 대해 알아보자.

### Region proposals

Region proposal의 방법들은 정말 다양하지만, 저자들은 [selective search 방법](chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/http://www.huppelen.nl/publications/selectiveSearchDraft.pdf)을 사용한다.
selective search 방법에 대해선 나도 자세히 모르지만.. 그냥 region proposal을 하기 위한 것이라고만 알고 넘어가자.

### Feature extraction

제안된 region들에 CNN을 적용해서 4096차원의 feature vector들을 추출한다. region의 크기가 다양한데, CNN의 입력 이미지는 227x227의 크기를 가져야해서 여차저차해서 크기를 맞춘다고 한다.
이것까진 자세하게 볼 필욘 없을 것 같다. 그리고 5개의 conv layer와 2개의 fc layer를 사용한다. 22년의 시점에서 보면 굉장히 귀여운 네트워크의 크기이다 ㅎㅎ

<br/>

## 2.2. Test-time detection

마지막으로 3단계다. 추출된 feature vector들을 linear SVM을 이용해서 클래스에 대한 score를 매긴다. 아마 가장 큰 score를 지닌 것은 예측 class 레이블로 가져가겠지.
2000개의 region들이 각각 label이 달려있을거고 여기에 non-maximum suppression을 적용하자. 이것에 대한 정리는 내가 한번 [블로그 글](https://yhyuntak.github.io/%EB%94%A5%EB%9F%AC%EB%8B%9D/object%20detection/object-detection%EC%97%90-%EB%8C%80%ED%95%B4%EC%84%9C-%EC%95%8C%EC%95%84%EB%B3%B4%EC%9E%90-STEP-1/)로 남긴 적이 있다.

그러면 한 이미지에서 non-maximum suppression을 적용한 결과로써 각각의 물체들에 대한 bbox와 score,클래스 레이블들이 저장되게 된다.

R-CNN의 장점들에 대해 설명이 되어있는데, 간추리면 다음과 같다.
* 기존의 방법들보다 feature의 차원이 줄어든다.
* 계산 속도가 빠르다.
* 한번에 천개 단위의 물체들의 클래스를 사용할 수 있다.

(이부분은 흘리면서 읽어서 아닐수도 있다. 내 목표는 네트워크 구조와 방법론에 대해 보는 것이기 때문에..!)

<br/>

## 2.3. Training

## Supervised pre-training

Introduction에서 말했듯이, bbox데이터로 학습하기 전에, 지도 사전 학습을 사용한다. bbox 데이터가 아마 만들기 힘들었나보다..
아마 ILSVRC2012 분류 데이터로 CNN을 한번 학습해서 표현력을 이끌어낸 상태에서 본 학습에 들어가는 것 같다.

## Domain-specific fine-tuning

저자들의 CNN 모델을 새로운 detection과 warped proposal windows에 적용하기 위해, SGD를 이용해서 학습을 한다.
이 때, ImageNet의 1000개의 클래스 데이터에서 랜덤하게 N+1개로 학습한 것으로 fine-tuning을 한다. 이 때, SGD의 learning rate는 크게 하면 기존의 pre-training한 weight들이
전부 무너지게 된다. 따라서 learning rate는 작고 아주 섬세하게 컨트롤해야한다.

pre-training과 fine-tuning에 대해 더 알고 싶다면, [한글 블로그](https://jeinalog.tistory.com/13) 혹은 [영어 블로그](https://towardsdatascience.com/transfer-learning-from-pre-trained-models-f2393f124751)를 참고하자.
아주 아주 좋은 글이다.

